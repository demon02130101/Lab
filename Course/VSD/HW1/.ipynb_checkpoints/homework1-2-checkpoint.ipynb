{"cells":[{"cell_type":"markdown","id":"04a61290","metadata":{"id":"04a61290"},"source":["# HW1-2: Model Inference of the Pretrained LeNet"]},{"cell_type":"markdown","id":"2a9c9ccd","metadata":{"id":"2a9c9ccd"},"source":["<font color='red'>Name: (Replace with your name) Student ID: (Replace with your Student ID) </font>"]},{"cell_type":"markdown","id":"AlhWgEF8SUV-","metadata":{"id":"AlhWgEF8SUV-"},"source":["## 0. Initial Setup\n","* Currently, Numba does not support Python 3.10 or higher versions. Therefore, if you are using Python versions 3.10 and above, **please downgrade to a lower version or switch to running it on Colab**\n","* If errors occur, it may be due to incompatibility between the versions of NumPy and Numba. You can try adding `!pip install numpy==1.18`. If the issue persists, consider switching to running it on Colab."]},{"cell_type":"code","execution_count":null,"id":"Isip8iMdSUV-","metadata":{"id":"Isip8iMdSUV-"},"outputs":[],"source":["#Uncomment the following line if you are on your local machine and facing issues with numpy. Comment it if you are on colab\n","#!pip install numpy==1.18\n","!pip install numba==0.55.1"]},{"cell_type":"code","execution_count":null,"id":"u8x2wQYRSUV_","metadata":{"id":"u8x2wQYRSUV_"},"outputs":[],"source":["import torch\n","from torch.utils.data import DataLoader\n","import torchvision\n","import torchvision.transforms as transforms\n","import json\n","import numpy as np\n","from functional import *"]},{"cell_type":"markdown","id":"42c9bca9","metadata":{"id":"42c9bca9"},"source":["## 1. High-level Function Implementation for Each Layer\n","Implement a high-level functional model for each layer of the CNN, including convolution, pooling, and\n","fully-connected layer with 8-bit quantization of the input activations, output activations, and weights accordingly.\n","* Learn how to use [Numba](https://numba.pydata.org/) to accelerate python functions\n","* Fill in the TODOs in `functional.py`.\n","    * You must consider `psum_range = (lower_bound, upper_bound)` which controls the precision of partial sums. That means the accumulation of activations will not exceed this range during the process of computing convolution and fully-connected layers.\n","    * `psum_record_list` will be used in *2. Bit-width of Partial Sums*, so you may leave it alone for now.\n","    \n","### 1.1 Pass all Unit Tests of `OpTestCase`.\n","First, use 32-bit signed integers for the partial sums to pass the unit tests. The accumulation of activations is limited to 32 bits in convolution and fully-connected layers. Clamp the value if it exceeds the minimum or maximum values of the 32-bit signed number.\n","\n","Note that you should implement convolution layers, fully-connected layers, and max-pooling layers with \"nested loops\" by yourself. You are not allowed to use existing functions (e.g., `conv2d` in `numpy` or `pytorch`). Or you will not get any credits. Raise questions when in doubt.\n","\n","There are eight unit tests you need to pass. If you intend to run part of them, follow the steps:\n","```\n","tests = ['test_C1', 'test_C3']\n","suite = unittest.TestSuite(map(OpTestCase, tests))\n","```"]},{"cell_type":"code","execution_count":null,"id":"tZYCwZcjSUV_","metadata":{"id":"tZYCwZcjSUV_"},"outputs":[],"source":["#unzip parameters.zip if needed\n","!unzip parameters.zip"]},{"cell_type":"code","execution_count":null,"id":"rtNleN7vAvWA","metadata":{"id":"rtNleN7vAvWA"},"outputs":[],"source":["import unittest\n","\n","class OpTestCase(unittest.TestCase):\n","\n","    def setUp(self):\n","        bit = 32\n","        self.number_range = (-(2**(bit-1)), 2**(bit-1) - 1)\n","        self.weightsDict, self.scalesDict = getWeightAndScale()\n","        self.max_samples = 100 #100\n","\n","\n","    def tearDown(self):\n","        self.weightsDict, self.scalesDict = None, None\n","        self.source = None\n","\n","    def test_C1(self):\n","        for i in range(self.max_samples):\n","            self.source = \"./activations/img{}/\".format(i)\n","            x = np.loadtxt(self.source+\"/conv1/input.csv\", delimiter=',').astype(int)\n","            x = x.reshape(1, 1, 32, 32)\n","            x, _ = Conv2d(self.number_range, x, self.weightsDict[\"conv1.conv\"], out_channels=6)\n","            x = x.flatten()\n","            x_ = np.loadtxt(self.source+\"/conv1/output.csv\", delimiter=',').astype(int)\n","            self.assertTrue(np.all(x == x_))\n","\n","    def test_ACTQUANT(self):\n","        for i in range(self.max_samples):\n","            self.source = \"./activations/img{}/\".format(i)\n","            x = np.loadtxt(self.source+\"/conv1/output.csv\", delimiter=',').astype(int)\n","            x = ActQuant(x, self.scalesDict[\"conv1.conv\"])\n","            x = ReLU(x).flatten()\n","            x_ = np.loadtxt(self.source+\"/maxpool2/input.csv\", delimiter=',').astype(int)\n","            self.assertTrue(np.all(x == x_))\n","\n","    def test_S2(self):\n","        for i in range(self.max_samples):\n","            self.source = \"./activations/img{}/\".format(i)\n","            x = np.loadtxt(self.source+\"/maxpool2/input.csv\", delimiter=',').astype(int)\n","            x = x.reshape(1, 6, 28, 28)\n","            x = MaxPool2d(x).flatten()\n","            x_ = np.loadtxt(self.source+\"/maxpool2/output.csv\", delimiter=',').astype(int)\n","            self.assertTrue(np.all(x == x_))\n","\n","    def test_C3(self):\n","        for i in range(self.max_samples):\n","            self.source = \"./activations/img{}/\".format(i)\n","            x = np.loadtxt(self.source+\"/conv3/input.csv\", delimiter=',').astype(int)\n","            x = x.reshape(1, 6, 14, 14)\n","            x, _ = Conv2d(self.number_range, x, self.weightsDict[\"conv3.conv\"], out_channels=16)\n","            x = x.flatten()\n","            x_ = np.loadtxt(self.source+\"/conv3/output.csv\", delimiter=',').astype(int)\n","            self.assertTrue(np.all(x == x_))\n","\n","    def test_S4(self):\n","        for i in range(self.max_samples):\n","            self.source = \"./activations/img{}/\".format(i)\n","            x = np.loadtxt(self.source+\"/maxpool4/input.csv\", delimiter=',').astype(int)\n","            x = x.reshape(1, 16, 10, 10)\n","            x = MaxPool2d(x).flatten()\n","            x_ = np.loadtxt(self.source+\"/maxpool4/output.csv\", delimiter=',').astype(int)\n","            self.assertTrue(np.all(x == x_))\n","\n","    def test_C5(self):\n","        for i in range(self.max_samples):\n","            self.source = \"./activations/img{}/\".format(i)\n","            x = np.loadtxt(self.source+\"/conv5/input.csv\", delimiter=',').astype(int)\n","            x = x.reshape(1, 16, 5, 5)\n","            x, _ = Conv2d(self.number_range, x, self.weightsDict[\"conv5.conv\"], out_channels=120)\n","            x = x.flatten()\n","            x_ = np.loadtxt(self.source+\"/conv5/output.csv\", delimiter=',').astype(int)\n","            self.assertTrue(np.all(x == x_))\n","\n","    def test_F6(self):\n","        for i in range(self.max_samples):\n","            self.source = \"./activations/img{}/\".format(i)\n","            x = np.loadtxt(self.source+\"/fc6/input.csv\", delimiter=',').astype(int)\n","            x = x.reshape(1, 120)\n","            x, _ = Linear(self.number_range, x, self.weightsDict[\"fc6.fc\"])\n","            x_ = np.loadtxt(self.source+\"/fc6/output.csv\", delimiter=',')\n","            self.assertTrue(np.all(x == x_))\n","\n","    def test_OUTPUT(self):\n","        for i in range(1,self.max_samples):\n","            self.source = \"./activations/img{}/\".format(i)\n","            x = np.loadtxt(self.source+\"/output/input.csv\", delimiter=',').astype(int)\n","            x = x.reshape(1, 84)\n","            x, _ = Linear(self.number_range, x, self.weightsDict[\"output.fc\"], self.weightsDict[\"outputBias\"])\n","            x_ = np.loadtxt(self.source+\"/output/output.csv\", delimiter=',')\n","            self.assertTrue(np.all(x == x_))\n"]},{"cell_type":"code","execution_count":null,"id":"87b1c981","metadata":{"id":"87b1c981"},"outputs":[],"source":["# tests = ['test_C1']\n","# suite = unittest.TestSuite(map(OpTestCase, tests))\n","suite = unittest.TestLoader().loadTestsFromTestCase(OpTestCase)\n","unittest.TextTestRunner(verbosity=2).run(suite)"]},{"cell_type":"markdown","id":"7c623abf","metadata":{"id":"7c623abf"},"source":["### 1.2 Reconstruct the LeNet in HW1\n","* Fill in the TODO in `forward()` of `LeNet` in `functional.py`.\n","* Test the model with the test dataset. There should be no accuracy degradation if you have done everything correctly."]},{"cell_type":"code","execution_count":null,"id":"BAKPeqz65wpG","metadata":{"id":"BAKPeqz65wpG"},"outputs":[],"source":["def test(model, dataloader: DataLoader, max_samples=None):\n","    cnt = 0\n","    total = 0\n","    n_inferences = 0\n","    for i, data in enumerate(dataloader):\n","\n","        images, labels = data[0].numpy(), data[1].numpy()\n","        y = model.forward(images)\n","\n","        y = np.argmax(y, axis=1)\n","        cnt = cnt + np.count_nonzero((labels == y) == True)\n","        total += images.shape[0]\n","\n","        if max_samples:\n","            n_inferences += images.shape[0]\n","            if n_inferences >= max_samples:\n","                break\n","\n","    print(\"Accuracy: {}%\".format(cnt/total*100))\n","    return cnt/total*100"]},{"cell_type":"code","execution_count":null,"id":"2639da05","metadata":{"id":"2639da05"},"outputs":[],"source":["transform = transforms.Compose(\n","    [\n","     transforms.Resize((32, 32)),\n","     transforms.ToTensor(),\n","     transforms.Normalize((0.5,), (0.5,))\n","    ])\n","\n","testset = torchvision.datasets.MNIST(root='./data', train=False,\n","                                       download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n","                                         shuffle=False, num_workers=2)\n","def run_LeNet(n_bit, max_samples = None):\n","    number_range = (-(2**(n_bit-1)), 2**(n_bit-1) - 1)\n","    print(\"bit:\", n_bit)\n","    print(\"bit-width range:\",number_range)\n","\n","    psum_range = {\n","        'c1': number_range,\n","        'c3': number_range,\n","        'c5': number_range,\n","        'f6': number_range,\n","        'output': number_range\n","    }\n","\n","    model = LeNet(psum_range)\n","\n","    return test(model, testloader)\n","\n","run_LeNet(n_bit = 32)"]},{"cell_type":"markdown","id":"8d44e4d9","metadata":{"id":"8d44e4d9"},"source":["## 2. Bit-width of Partial Sums\n","### 2.1 Question: Find the minimum bit-width of partial sums for all layers with the highest accuracy\n","1. Use matplotlib to plot \"Test Accuracy(%)\" versus \"Bit-width of Partial Sums\" for \"Bit-width of Partial Sums\" in $[2, 32]$ by `matplotlib.pyplot.plot()` and put result in the report.\n","    * [Plot with matplotlib](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html).\n","2. What is the smallest bit-width of partial sums that maintains the same accuracy from the previous plot?"]},{"cell_type":"code","execution_count":null,"id":"3c93f393","metadata":{"id":"3c93f393"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","acc = []\n","for i in range(1, 17):\n","    acc.append(run_LeNet(i*2))\n","\n","# TODO\n"]},{"cell_type":"markdown","id":"6127ac58","metadata":{"id":"6127ac58"},"source":["### 2.2 Question: Find the minimum bit-width of partial sums for each layer without hurting the accuracy\n","1. Plot the distribution of partial sums of each quantized layer in the CNN with the MNIST test dataset and put the result in report. Write down the min, max, and standard deviation for each layer.\n","    * Check the TODO in `LeNet` of `functional.py`. You should save all partial sums to the dictionary, `psum_record_dict`.\n","    * We can get this dictionary after running the model with the first image in the test dataset by `model.psum_record_dict`.\n","2. Determine the minimum bit-width of partial sums in each layer without hurting the accuracy.\n","    * Fill in the TODO to see if the accuracy is still the same.\n","    * Show the accuracy in the report after doing so."]},{"cell_type":"code","execution_count":null,"id":"80d07474","metadata":{"id":"80d07474"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","n_bit = 32\n","number_range = (-(2**(n_bit-1)), 2**(n_bit-1) - 1)\n","print(\"bit:\", n_bit)\n","print(\"bit-width range:\",number_range)\n","\n","psum_range = {\n","    'c1': number_range,\n","    'c3': number_range,\n","    'c5': number_range,\n","    'f6': number_range,\n","    'output': number_range\n","}\n","\n","model = LeNet(psum_range)\n","\n","image = np.expand_dims(testset[0][0], axis=0)\n","_ = model.forward(image, psum_record = True)\n","\n","# TODO\n","# Plot the distribution of partial sums of each quantized layer in the CNN\n"]},{"cell_type":"code","execution_count":null,"id":"d1d17e5f","metadata":{"id":"d1d17e5f"},"outputs":[],"source":["# TODO\n","# Test your model with those Bit-widths you choose\n","psum_range = {\n","    'c1': ...,\n","    'c3': ...,\n","    'c5': ...,\n","    'f6': ...,\n","    'output': ...\n","}\n","\n","model = LeNet(psum_range)\n","\n","_ = test(model, testloader)\n"]},{"cell_type":"markdown","id":"f718967b","metadata":{"id":"f718967b"},"source":["## 3. Evaluation: Energy Model\n","### 3.1 Question: Evaluate these two approaches based on the following energy model:\n","$$E_w = s_{mul}\\times N_{mul} + s_{add}\\times N_{add},$$\n","$$s_{mul} = \\alpha\\times \\left(\\frac{B_{mul}}{8}\\right)^2,\\ \\alpha = 64,$$\n","$$s_{add} = \\beta\\times B_{add}, \\ \\beta=1,$$\n","The variables $N_{mul}$ and $N_{add}$ represent the number of multiplications and additions in your dataflow, respectively. It's possible to calculate the $N_{mul}$ and $N_{add}$ of each layer by hand. The variables $B_{mul}$ and $B_{add}$ denote the bit-widths of multiplier and adder, respectively. The constants α and β are provided to model the energy scaling factor of multiplication and addition, respectively. Additionally, $s_{mul}$ represents the energy cost per multiplication, which is proportional to the square of the multiplier’s bit-width. On the other hand, $s_{add}$ denotes the energy cost per addition, which is linearly proportional to the adder’s bit-width. For instance, in our estimation model, a 4-bit multiplier has an energy cost per multiplication of 16, which is computed as 64 x (4/8)^2.\n","* You must accumulate the energy layer by layer to obtain the overall $E_w$, if each layer has a  different $B_{mul}$ or $B_{add}$.\n","* We only consider convolution and fully-connected operations, ignoring pooling and ReLU operations in this energy model.\n","* Disclaimer: Note that this energy model is artificial and oversimplified. DO NOT apply it to your research work.\n","\n","1. Calculate the overall $E_w$ with minimum bit-width for the setup of 2.1.\n","2. Calculate the energy layer by layer and also the overall $E_w$ for the setup of 2.2."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":5}